{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68b493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for GRF, socio variables\n",
    "# Take Dataset3 NYC for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39f0a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da52e41",
   "metadata": {},
   "source": [
    "# Geographical RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35563982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeographicalRandomForest:\n",
    "    # this is the initialization function\n",
    "    # param local_model_num controls how many local models will participate in prediction; default is 1 !!!New\n",
    "    def __init__(self, ntree, mtry, band_width, local_weight, local_model_num=1, bootstrap=False, random_seed=42):\n",
    "        self.ntree = ntree\n",
    "        self.mtry = mtry\n",
    "        self.band_width = band_width\n",
    "        self.local_weight = local_weight\n",
    "        self.local_model_num = local_model_num\n",
    "        self.bootstrap=bootstrap\n",
    "        self.random_seed = random_seed\n",
    "        self.global_model = None\n",
    "        self.local_models = None\n",
    "        self.train_data_coords = None\n",
    "        self.distance_matrix = None\n",
    "        self.train_data_index = None\n",
    "        self.train_data_columns = None\n",
    "       \n",
    "    \n",
    "    # param X_train contains a data frame of the the training indepdent variables \n",
    "    # param y_train contains a data series of the target dependent variable\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    # param record_index contains a data series of the indices of the data for helping store local models\n",
    "    def fit(self, X_train, y_train, coords, record_index):\n",
    "        \n",
    "        # save the index of the training data\n",
    "        self.train_data_index = record_index\n",
    "        self.train_data_columns = X_train.columns\n",
    "        \n",
    "        # get Global RF model and importance information, and save global RF model\n",
    "        rf_global = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = self.ntree, max_features = self.mtry, random_state = self.random_seed) \n",
    "        rf_global.fit(X_train, y_train)\n",
    "        self.global_model = rf_global\n",
    "        \n",
    "        \n",
    "        # create an empty dictionary for local models\n",
    "        self.local_models = {}\n",
    "        \n",
    "        # get the distance matrix between the training geographic features\n",
    "        coords_array = np.array(coords, dtype = np.float64) # translate (x,y) to array type\n",
    "        self.train_data_coords = coords_array\n",
    "        self.distance_matrix = distance.cdist(coords_array,coords_array, 'euclidean') # calculate Euclidean Distance\n",
    "        \n",
    "        # train local models\n",
    "        for i in range(len(X_train)):\n",
    "            distance_array = self.distance_matrix[i]\n",
    "            idx = np.argpartition(distance_array, self.band_width)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.band_width]  # only those indices within the band_width are valid \n",
    "            \n",
    "            local_X_train = X_train.iloc[idx]\n",
    "            local_y_train = y_train.iloc[idx]\n",
    "            \n",
    "            # make local tree size smaller, because there is no sufficient data to train a big tree !!!New\n",
    "            local_tree_size = int(self.ntree * (self.band_width*1.0/len(X_train)))\n",
    "            if local_tree_size < 1:\n",
    "                local_tree_size = 1  # local tree size should be at least 1\n",
    "             \n",
    "            # get local model\n",
    "            rf_local = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = local_tree_size, max_features = self.mtry, random_state = self.random_seed) # input\n",
    "            rf_local.fit(local_X_train, local_y_train)\n",
    "            \n",
    "            # key for storing local rf model in a dictionary\n",
    "            rf_local_key = str(record_index.iloc[i])+\"|\"+ str(coords_array[i][0])+\"|\"+str(coords_array[i][1])\n",
    "            self.local_models[rf_local_key] = rf_local\n",
    "            \n",
    "    \n",
    "    # the function for making predictions using the GRF model\n",
    "    # param X_test contains a data frame of the independent variables in the test dataset\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    def predict(self, X_test, coords_test): \n",
    "        \n",
    "        # first, make prediction using the global RF model \n",
    "        predict_global = self.global_model.predict(X_test).flatten() # get the global predict y first\n",
    "        \n",
    "        # Second, make prediction using the local RF model \n",
    "        coords_test_array = np.array(coords_test, dtype = np.float64)\n",
    "        distance_matrix_test_to_train = distance.cdist(coords_test_array, self.train_data_coords, 'euclidean')\n",
    "        predict_local = []\n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            distance_array = distance_matrix_test_to_train[i]\n",
    "            idx = np.argpartition(distance_array, self.local_model_num)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.local_model_num]\n",
    "            \n",
    "            this_local_prediction = 0\n",
    "            for this_idx in idx:\n",
    "                local_model_key = str(self.train_data_index.iloc[this_idx])+\"|\"+ str(self.train_data_coords[this_idx][0])+\"|\"+str(self.train_data_coords[this_idx][1])\n",
    "                local_model = self.local_models[local_model_key]\n",
    "                this_local_prediction += local_model.predict(X_test[i:i+1]).flatten()[0]\n",
    "            \n",
    "            this_local_prediction = this_local_prediction*1.0 / self.local_model_num  # average local predictions\n",
    "            predict_local.append(this_local_prediction)\n",
    "          \n",
    "        \n",
    "        # Third, combine global and local predictions\n",
    "        predict_combined = []\n",
    "        for i in range(len(predict_global)):\n",
    "            this_combined_prediction = predict_local[i]*self.local_weight + predict_global[i]*(1-self.local_weight) \n",
    "            predict_combined.append(this_combined_prediction)\n",
    "        \n",
    "        \n",
    "        return predict_combined, predict_global, predict_local   # return three types of predictions\n",
    "    \n",
    "    \n",
    "    # this function outputs the local feature importance based on the local models\n",
    "    def get_local_feature_importance(self):\n",
    "        if self.local_models == None:\n",
    "            print(\"The model has not been trained yet...\")\n",
    "            return None\n",
    "        \n",
    "        column_list = [self.train_data_index.name] \n",
    "        for column_name in self.train_data_columns: \n",
    "            column_list.append(column_name) \n",
    "            \n",
    "        feature_importance_df = pd.DataFrame(columns = column_list) \n",
    "        \n",
    "        for model_key in self.local_models.keys():\n",
    "            model_info = model_key.split(\"|\")\n",
    "            this_local_model = self.local_models[model_key]\n",
    "            this_row = {}\n",
    "            this_row[self.train_data_index.name] = model_info[0] # the index of a row\n",
    "            for feature_index in range(0, len(self.train_data_columns)):\n",
    "                this_row[self.train_data_columns[feature_index]]=this_local_model.feature_importances_[feature_index]\n",
    "            \n",
    "            feature_importance_df = feature_importance_df.append(this_row, ignore_index = True) # TypeError: Can only append a dict if ignore_index=True\n",
    "            \n",
    "            \n",
    "        return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f85808",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "613d867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_socio = pd.read_csv(\"../02 Dataset/05 Dataset 3/Socio_NYC.csv\") #input\n",
    "ct_shp = gpd.read_file(\"../02 Dataset/07 Coordinates info for GWR/NYC_CDC data_Tract_Ob_pro.shp\") # input\n",
    "ct_shp['GEOID'] = ct_shp['GEOID'].astype('int64')\n",
    "X_socio_1 = X_socio.merge(ct_shp, left_on = 'GEOID', right_on = 'GEOID', how = 'left')\n",
    "X_socio_2 = X_socio_1.set_index('GEOID')\n",
    "Y_2 = X_socio_2.pop('obesity_cr')\n",
    "del X_socio_2['geometry']\n",
    "len(X_socio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7fbedf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(data, stats):\n",
    "    return (data - stats['mean'])/ stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b7b02",
   "metadata": {},
   "source": [
    "# GRF 10K-Fold local_w = 1, local_model_num = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26b793ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: [  29   49   56   65   69   70   99  109  111  120  124  128  135  211\n",
      "  212  231  233  237  239  251  254  256  270  281  298  305  306  307\n",
      "  316  324  342  344  350  353  361  366  367  368  382  383  394  411\n",
      "  414  416  420  422  427  429  433  450  464  480  483  485  486  514\n",
      "  526  527  530  532  548  552  554  561  570  581  582  583  602  614\n",
      "  617  630  679  741  743  752  756  759  785  798  819  824  843  849\n",
      "  881  889  892  903  915  921  926  930  932  940  949  950  988  999\n",
      " 1001 1009 1052 1087 1106 1113 1116 1118 1125 1137 1160 1169 1176 1177\n",
      " 1182 1216 1221 1234 1235 1242 1244 1252 1255 1268 1270 1273 1274 1284\n",
      " 1285 1287 1298 1303 1305 1316 1318 1322 1341 1343 1344 1357 1359 1379\n",
      " 1384 1386 1412 1428 1429 1444 1448 1469 1476 1490 1497 1506 1531 1532\n",
      " 1563 1573 1593 1594 1600 1604 1616 1619 1647 1659 1668 1671 1673 1675\n",
      " 1681 1684 1686 1716 1720 1726 1732 1736 1740 1758 1764 1770 1784 1810\n",
      " 1813 1814 1820 1855 1856 1867 1907 1918 1926 1934 1935 1936 1940 1952\n",
      " 1954 1982 1985 1987]\n",
      "TEST: [  23   30   32   44   45   59   63   67   73   76   78  100  115  123\n",
      "  162  163  168  173  175  185  188  194  196  203  210  218  220  240\n",
      "  247  261  266  275  289  297  303  322  331  351  352  354  374  393\n",
      "  438  453  462  471  478  495  507  519  534  535  538  544  567  572\n",
      "  576  579  588  596  607  610  619  650  651  654  693  705  706  710\n",
      "  727  730  757  772  777  780  782  787  788  818  829  836  904  905\n",
      "  909  922  936  937  939  944  963  973  985  987  990  993  998 1007\n",
      " 1010 1023 1034 1043 1063 1078 1080 1085 1089 1102 1103 1105 1107 1124\n",
      " 1132 1133 1163 1226 1230 1231 1240 1247 1251 1263 1269 1271 1286 1288\n",
      " 1301 1304 1307 1309 1314 1331 1355 1360 1362 1364 1368 1376 1378 1385\n",
      " 1402 1405 1406 1418 1425 1435 1457 1471 1487 1488 1507 1516 1525 1543\n",
      " 1545 1549 1553 1557 1560 1561 1562 1568 1574 1587 1588 1605 1612 1623\n",
      " 1629 1635 1641 1649 1653 1664 1682 1708 1734 1756 1778 1779 1793 1794\n",
      " 1816 1833 1847 1901 1911 1914 1916 1919 1925 1927 1929 1933 1938 1945\n",
      " 1951 1956 1960 1988]\n",
      "TEST: [   2   15   43   51   71   72  101  107  141  148  170  182  184  192\n",
      "  198  199  226  244  250  259  265  271  272  273  274  292  300  309\n",
      "  310  311  332  334  339  365  371  376  381  398  405  408  413  415\n",
      "  425  426  432  436  439  445  465  479  481  482  494  497  506  518\n",
      "  529  543  555  557  575  584  585  590  591  593  599  611  613  618\n",
      "  620  628  674  678  680  692  704  707  712  715  720  733  736  744\n",
      "  745  765  767  774  792  806  812  813  817  832  838  845  859  888\n",
      "  907  914  931  948  962  966  976  982  986 1018 1050 1053 1055 1058\n",
      " 1061 1073 1075 1083 1091 1094 1151 1164 1165 1204 1210 1232 1237 1278\n",
      " 1281 1292 1302 1313 1317 1319 1323 1328 1336 1351 1352 1380 1383 1389\n",
      " 1392 1395 1407 1421 1433 1436 1449 1453 1454 1455 1460 1480 1509 1523\n",
      " 1544 1546 1548 1550 1559 1565 1602 1608 1609 1624 1628 1630 1640 1642\n",
      " 1644 1646 1674 1680 1691 1693 1731 1733 1746 1754 1767 1775 1798 1826\n",
      " 1827 1840 1864 1869 1871 1879 1900 1906 1917 1922 1932 1949 1957 1971\n",
      " 1975 1984 1990 1993]\n",
      "TEST: [   6   18   31   48   54   58   81   83   84   86  105  113  118  126\n",
      "  147  155  174  177  179  181  208  214  221  236  243  277  285  286\n",
      "  287  296  308  312  326  327  329  341  346  358  360  363  370  377\n",
      "  380  423  428  430  435  442  451  457  461  468  490  493  500  505\n",
      "  513  522  528  551  560  566  589  598  601  609  621  629  631  637\n",
      "  643  660  669  670  677  694  700  701  721  722  746  755  764  771\n",
      "  781  802  807  809  862  869  873  874  886  900  906  916  923  943\n",
      "  952  968  974  978  994 1005 1006 1013 1022 1027 1029 1036 1047 1054\n",
      " 1100 1110 1114 1144 1159 1178 1187 1190 1196 1198 1200 1202 1222 1225\n",
      " 1310 1315 1330 1333 1338 1340 1342 1381 1394 1403 1417 1461 1467 1470\n",
      " 1475 1505 1541 1554 1555 1572 1578 1581 1582 1592 1599 1607 1610 1614\n",
      " 1617 1625 1632 1645 1669 1670 1672 1683 1692 1696 1719 1721 1738 1747\n",
      " 1749 1759 1760 1766 1776 1777 1780 1788 1800 1805 1807 1823 1835 1837\n",
      " 1839 1841 1854 1857 1863 1882 1893 1894 1898 1915 1930 1955 1967 1969\n",
      " 1972 1973 1980 1981]\n",
      "TEST: [  10   12   25   41   88   96  129  131  138  139  140  142  156  158\n",
      "  164  167  171  178  193  195  209  215  224  258  260  282  290  291\n",
      "  294  299  318  319  323  325  328  333  348  355  375  390  409  410\n",
      "  419  421  440  447  458  477  503  516  531  549  553  558  571  573\n",
      "  578  597  615  626  634  636  649  664  668  672  682  695  711  714\n",
      "  723  724  754  778  786  799  808  810  816  820  834  839  841  844\n",
      "  855  857  861  864  865  867  879  887  893  901  910  917  925  938\n",
      "  941  942  946  964  965  979  984  997 1000 1004 1033 1037 1040 1057\n",
      " 1067 1090 1096 1112 1121 1128 1138 1157 1173 1175 1192 1193 1211 1228\n",
      " 1233 1239 1245 1261 1262 1272 1290 1334 1339 1345 1353 1356 1401 1404\n",
      " 1420 1422 1423 1424 1427 1432 1450 1452 1456 1463 1466 1486 1493 1494\n",
      " 1511 1521 1524 1530 1536 1558 1569 1586 1611 1613 1639 1654 1655 1689\n",
      " 1701 1712 1727 1729 1744 1752 1755 1761 1797 1819 1822 1832 1848 1849\n",
      " 1850 1851 1853 1859 1866 1868 1881 1888 1891 1892 1897 1921 1924 1928\n",
      " 1939 1961 1970 1986]\n",
      "TEST: [   0    3    5    7   24   27   33   39   42   47   52   55   60   62\n",
      "   66   68   74   77   80   82   85   92   94   97  102  104  106  110\n",
      "  117  125  132  136  137  144  165  183  204  213  222  227  228  232\n",
      "  235  238  242  248  249  267  280  302  314  321  336  349  359  362\n",
      "  364  388  404  424  434  446  448  467  523  525  533  536  541  542\n",
      "  545  547  594  603  605  622  624  638  644  661  665  666  673  676\n",
      "  688  691  716  718  737  762  770  793  796  803  811  826  842  846\n",
      "  847  858  898  899  918  983  989 1026 1030 1041 1046 1049 1068 1074\n",
      " 1079 1084 1101 1108 1111 1117 1120 1131 1134 1146 1161 1170 1179 1181\n",
      " 1185 1189 1206 1208 1220 1223 1249 1258 1259 1283 1289 1293 1299 1324\n",
      " 1326 1329 1335 1350 1361 1370 1374 1431 1440 1446 1447 1458 1468 1472\n",
      " 1474 1477 1483 1492 1498 1501 1502 1503 1512 1517 1538 1542 1567 1571\n",
      " 1575 1583 1601 1606 1615 1637 1662 1665 1666 1694 1706 1709 1723 1735\n",
      " 1781 1786 1789 1799 1811 1812 1829 1860 1861 1885 1904 1909 1941 1958\n",
      " 1964 1968 1989]\n",
      "TEST: [   9   11   28   36   38   57   61   75   79   89   90  108  114  133\n",
      "  145  169  172  176  191  223  234  255  264  278  284  338  347  357\n",
      "  372  373  386  389  395  396  412  417  444  449  454  456  460  475\n",
      "  491  498  499  501  504  539  568  587  595  604  616  652  657  662\n",
      "  667  671  675  697  708  713  717  728  731  732  734  735  738  739\n",
      "  750  753  760  783  814  823  825  828  848  850  852  868  872  875\n",
      "  882  884  885  890  894  908  912  919  924  933  934  945  947  953\n",
      "  958  967  969  970  977 1024 1031 1032 1035 1042 1048 1065 1088 1093\n",
      " 1097 1098 1140 1142 1145 1149 1155 1156 1167 1168 1172 1174 1188 1197\n",
      " 1201 1205 1209 1214 1217 1229 1236 1253 1265 1276 1280 1296 1320 1325\n",
      " 1347 1358 1366 1375 1387 1391 1393 1399 1414 1419 1441 1442 1464 1465\n",
      " 1481 1489 1491 1510 1514 1518 1519 1526 1537 1551 1566 1576 1596 1618\n",
      " 1622 1627 1652 1667 1679 1688 1710 1730 1742 1769 1783 1801 1802 1804\n",
      " 1808 1809 1815 1821 1824 1844 1852 1873 1878 1884 1887 1905 1912 1913\n",
      " 1931 1953 1983]\n",
      "TEST: [   4   16   17   19   22   35   46   50   93  116  119  127  149  153\n",
      "  154  157  159  180  190  217  245  257  263  268  283  301  304  313\n",
      "  320  335  340  356  369  399  407  431  443  470  473  476  487  489\n",
      "  496  511  512  515  517  521  537  546  559  569  574  580  606  625\n",
      "  633  635  653  655  656  658  684  685  689  690  696  703  726  740\n",
      "  758  761  768  773  784  789  790  797  801  822  827  830  833  837\n",
      "  851  853  866  876  895  902  911  920  927  935  959  961  971  980\n",
      "  991  992  996 1002 1003 1008 1011 1015 1019 1039 1062 1066 1069 1070\n",
      " 1072 1077 1081 1092 1099 1115 1119 1127 1139 1141 1148 1150 1166 1191\n",
      " 1195 1199 1203 1212 1213 1219 1227 1243 1246 1260 1277 1279 1295 1308\n",
      " 1311 1312 1346 1348 1365 1373 1377 1416 1473 1504 1535 1539 1540 1547\n",
      " 1552 1556 1564 1580 1591 1620 1626 1651 1656 1657 1660 1677 1690 1702\n",
      " 1703 1704 1711 1713 1718 1737 1739 1741 1773 1782 1785 1787 1791 1825\n",
      " 1828 1870 1874 1876 1902 1903 1942 1944 1950 1959 1963 1966 1974 1978\n",
      " 1979 1992 1994]\n",
      "TEST: [   1    8   26   37   53  103  112  122  143  146  150  151  152  160\n",
      "  186  197  202  207  219  225  229  246  253  262  279  293  317  345\n",
      "  384  400  402  403  437  441  452  463  469  472  488  509  524  540\n",
      "  550  556  577  586  608  623  627  632  639  640  641  645  648  659\n",
      "  663  681  687  698  709  749  751  795  800  821  835  854  877  880\n",
      "  883  896  913  928  951  954  956  972  981 1012 1014 1045 1059 1060\n",
      " 1109 1122 1135 1136 1143 1147 1153 1158 1171 1183 1186 1194 1207 1218\n",
      " 1224 1248 1250 1254 1256 1257 1266 1282 1291 1300 1306 1321 1327 1349\n",
      " 1354 1371 1372 1382 1388 1397 1398 1400 1408 1409 1410 1415 1426 1434\n",
      " 1438 1439 1443 1445 1462 1479 1496 1520 1527 1529 1533 1534 1589 1595\n",
      " 1603 1621 1631 1633 1634 1636 1643 1648 1650 1658 1661 1663 1676 1678\n",
      " 1695 1697 1699 1700 1707 1715 1717 1722 1728 1743 1745 1753 1763 1765\n",
      " 1768 1771 1774 1790 1803 1817 1818 1830 1831 1834 1838 1843 1858 1872\n",
      " 1875 1877 1880 1883 1889 1896 1908 1910 1920 1923 1937 1943 1947 1948\n",
      " 1962 1976 1977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: [  13   14   20   21   34   40   64   87   91   95   98  121  130  134\n",
      "  161  166  187  189  200  201  205  206  216  230  241  252  269  276\n",
      "  288  295  315  330  337  343  378  379  385  387  391  392  397  401\n",
      "  406  418  455  459  466  474  484  492  502  508  510  520  562  563\n",
      "  564  565  592  600  612  642  646  647  683  686  699  702  719  725\n",
      "  729  742  747  748  763  766  769  775  776  779  791  794  804  805\n",
      "  815  831  840  856  860  863  870  871  878  891  897  929  955  957\n",
      "  960  975  995 1016 1017 1020 1021 1025 1028 1038 1044 1051 1056 1064\n",
      " 1071 1076 1082 1086 1095 1104 1123 1126 1129 1130 1152 1154 1162 1180\n",
      " 1184 1215 1238 1241 1264 1267 1275 1294 1297 1332 1337 1363 1367 1369\n",
      " 1390 1396 1411 1413 1430 1437 1451 1459 1478 1482 1484 1485 1495 1499\n",
      " 1500 1508 1513 1515 1522 1528 1570 1577 1579 1584 1585 1590 1597 1598\n",
      " 1638 1685 1687 1698 1705 1714 1724 1725 1748 1750 1751 1757 1762 1772\n",
      " 1792 1795 1796 1806 1836 1842 1845 1846 1862 1865 1886 1890 1895 1899\n",
      " 1946 1965 1991]\n"
     ]
    }
   ],
   "source": [
    "y_rf_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "ten_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in ten_fold.split(X_socio_2):\n",
    "    print(\"TEST:\", test_index)\n",
    "\n",
    "    X_train_1, X_test_1 = X_socio_2.iloc[train_index], X_socio_2.iloc[test_index]\n",
    "    y_train, y_test = Y_2.iloc[train_index], Y_2.iloc[test_index]\n",
    "    X_train = X_train_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density']]\n",
    "    X_test = X_test_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density']]\n",
    "    xy_coord = X_train_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    train_index_1 = X_train.index\n",
    "    train_index = pd.Series(train_index_1)\n",
    "    coords_test = X_test_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    grf = GeographicalRandomForest(560, 7, 220, 1, local_model_num = 38) \n",
    "    grf.fit(scaled_X_train, y_train, xy_coord, train_index)\n",
    "    \n",
    "    predict_combined, predict_global, predict_local = grf.predict(scaled_X_test,coords_test)\n",
    "    y_rf_socio_predict = y_rf_socio_predict + predict_combined\n",
    "    y_true = y_true + y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfcccf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_socio_rmse = mean_squared_error(y_true , y_rf_socio_predict, squared=False) #False means return RMSE value\n",
    "rf_socio_r2 = r2_score(y_true, y_rf_socio_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4e7dc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the RF model with sociodemographic predictors: 1.5078393544953197\n",
      "R2 of the RF model with sociodemographic predictors: 0.9343616631876094\n"
     ]
    }
   ],
   "source": [
    "# sociodemographic - estimators\n",
    "print(\"RMSE of the RF model with sociodemographic predictors: \"+str(rf_socio_rmse))\n",
    "print(\"R2 of the RF model with sociodemographic predictors: \"+str(rf_socio_r2)) # For R2, I took this one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
