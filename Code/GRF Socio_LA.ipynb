{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3881146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for GRF, socio variables\n",
    "# Take Dataset3 LA for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe69a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc2d28",
   "metadata": {},
   "source": [
    "# Geographical RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeographicalRandomForest:\n",
    "    # this is the initialization function\n",
    "    # param local_model_num controls how many local models will participate in prediction; default is 1 !!!New\n",
    "    def __init__(self, ntree, mtry, band_width, local_weight, local_model_num=1, bootstrap=False, random_seed=42):\n",
    "        self.ntree = ntree\n",
    "        self.mtry = mtry\n",
    "        self.band_width = band_width\n",
    "        self.local_weight = local_weight\n",
    "        self.local_model_num = local_model_num\n",
    "        self.bootstrap=bootstrap\n",
    "        self.random_seed = random_seed\n",
    "        self.global_model = None\n",
    "        self.local_models = None\n",
    "        self.train_data_coords = None\n",
    "        self.distance_matrix = None\n",
    "        self.train_data_index = None\n",
    "        self.train_data_columns = None\n",
    "       \n",
    "    \n",
    "    # param X_train contains a data frame of the the training indepdent variables \n",
    "    # param y_train contains a data series of the target dependent variable\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    # param record_index contains a data series of the indices of the data for helping store local models\n",
    "    def fit(self, X_train, y_train, coords, record_index):\n",
    "        \n",
    "        # save the index of the training data\n",
    "        self.train_data_index = record_index\n",
    "        self.train_data_columns = X_train.columns\n",
    "        \n",
    "        # get Global RF model and importance information, and save global RF model\n",
    "        rf_global = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = self.ntree, max_features = self.mtry, random_state = self.random_seed) \n",
    "        rf_global.fit(X_train, y_train)\n",
    "        self.global_model = rf_global\n",
    "        \n",
    "        \n",
    "        # create an empty dictionary for local models\n",
    "        self.local_models = {}\n",
    "        \n",
    "        # get the distance matrix between the training geographic features\n",
    "        coords_array = np.array(coords, dtype = np.float64) # translate (x,y) to array type\n",
    "        self.train_data_coords = coords_array\n",
    "        self.distance_matrix = distance.cdist(coords_array,coords_array, 'euclidean') # calculate Euclidean Distance\n",
    "        \n",
    "        # train local models\n",
    "        for i in range(len(X_train)):\n",
    "            distance_array = self.distance_matrix[i]\n",
    "            idx = np.argpartition(distance_array, self.band_width)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.band_width]  # only those indices within the band_width are valid \n",
    "            \n",
    "            local_X_train = X_train.iloc[idx]\n",
    "            local_y_train = y_train.iloc[idx]\n",
    "            \n",
    "            # make local tree size smaller, because there is no sufficient data to train a big tree !!!New\n",
    "            local_tree_size = int(self.ntree * (self.band_width*1.0/len(X_train)))\n",
    "            if local_tree_size < 1:\n",
    "                local_tree_size = 1  # local tree size should be at least 1\n",
    "             \n",
    "            # get local model\n",
    "            rf_local = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = local_tree_size, max_features = self.mtry, random_state = self.random_seed) # input\n",
    "            rf_local.fit(local_X_train, local_y_train)\n",
    "            \n",
    "            # key for storing local rf model in a dictionary\n",
    "            rf_local_key = str(record_index.iloc[i])+\"|\"+ str(coords_array[i][0])+\"|\"+str(coords_array[i][1])\n",
    "            self.local_models[rf_local_key] = rf_local\n",
    "            \n",
    "    \n",
    "    # the function for making predictions using the GRF model\n",
    "    # param X_test contains a data frame of the independent variables in the test dataset\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    def predict(self, X_test, coords_test): \n",
    "        \n",
    "        # first, make prediction using the global RF model \n",
    "        predict_global = self.global_model.predict(X_test).flatten() # get the global predict y first\n",
    "        \n",
    "        # Second, make prediction using the local RF model \n",
    "        coords_test_array = np.array(coords_test, dtype = np.float64)\n",
    "        distance_matrix_test_to_train = distance.cdist(coords_test_array, self.train_data_coords, 'euclidean')\n",
    "        predict_local = []\n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            distance_array = distance_matrix_test_to_train[i]\n",
    "            idx = np.argpartition(distance_array, self.local_model_num)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.local_model_num]\n",
    "            \n",
    "            this_local_prediction = 0\n",
    "            for this_idx in idx:\n",
    "                local_model_key = str(self.train_data_index.iloc[this_idx])+\"|\"+ str(self.train_data_coords[this_idx][0])+\"|\"+str(self.train_data_coords[this_idx][1])\n",
    "                local_model = self.local_models[local_model_key]\n",
    "                this_local_prediction += local_model.predict(X_test[i:i+1]).flatten()[0]\n",
    "            \n",
    "            this_local_prediction = this_local_prediction*1.0 / self.local_model_num  # average local predictions\n",
    "            predict_local.append(this_local_prediction)\n",
    "          \n",
    "        \n",
    "        # Third, combine global and local predictions\n",
    "        predict_combined = []\n",
    "        for i in range(len(predict_global)):\n",
    "            this_combined_prediction = predict_local[i]*self.local_weight + predict_global[i]*(1-self.local_weight) \n",
    "            predict_combined.append(this_combined_prediction)\n",
    "        \n",
    "        \n",
    "        return predict_combined, predict_global, predict_local   # return three types of predictions\n",
    "    \n",
    "    \n",
    "    # this function outputs the local feature importance based on the local models\n",
    "    def get_local_feature_importance(self):\n",
    "        if self.local_models == None:\n",
    "            print(\"The model has not been trained yet...\")\n",
    "            return None\n",
    "        \n",
    "        column_list = [self.train_data_index.name] \n",
    "        for column_name in self.train_data_columns: \n",
    "            column_list.append(column_name) \n",
    "            \n",
    "        feature_importance_df = pd.DataFrame(columns = column_list) \n",
    "        \n",
    "        for model_key in self.local_models.keys():\n",
    "            model_info = model_key.split(\"|\")\n",
    "            this_local_model = self.local_models[model_key]\n",
    "            this_row = {}\n",
    "            this_row[self.train_data_index.name] = model_info[0] # the index of a row\n",
    "            for feature_index in range(0, len(self.train_data_columns)):\n",
    "                this_row[self.train_data_columns[feature_index]]=this_local_model.feature_importances_[feature_index]\n",
    "            \n",
    "            feature_importance_df = feature_importance_df.append(this_row, ignore_index = True) # TypeError: Can only append a dict if ignore_index=True\n",
    "            \n",
    "            \n",
    "        return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f93f58",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd89581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_socio = pd.read_csv(\"../02 Dataset/05 Dataset 3/Socio_LA.csv\") #input\n",
    "ct_shp = gpd.read_file(\"../02 Dataset/07 Coordinates info for GWR/LA_CDC data_Tract_Ob_pro.shp\") # input\n",
    "ct_shp['GEOID'] = ct_shp['GEOID'].astype('int64')\n",
    "X_socio_1 = X_socio.merge(ct_shp, left_on = 'GEOID', right_on = 'GEOID', how = 'left')\n",
    "X_socio_2 = X_socio_1.set_index('GEOID')\n",
    "Y_2 = X_socio_2.pop('obesity_cr')\n",
    "del X_socio_2['geometry']\n",
    "len(X_socio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7a37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(data, stats):\n",
    "    return (data - stats['mean'])/ stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59caa46f",
   "metadata": {},
   "source": [
    "# GRF 10K-Fold local_w = 0.5, local_model_num = 40 ☆☆☆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cc5568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: [ 23  30  39  44  59  63  67  70  72  76  86  88  96 107 120 136 139 165\n",
      " 168 198 208 209 215 218 247 250 259 260 265 275 280 292 294 298 310 312\n",
      " 327 331 332 333 363 365 377 388 394 439 449 453 457 464 465 478 481 495\n",
      " 500 513 518 519 527 541 554 559 569 589 591 599 616 617 643 644 653 658\n",
      " 673 679 684 695 708 753 762 767 777 778 783 792 804 816 826 850 858 874\n",
      " 883 908 926 932 942]\n",
      "TEST: [ 31  33  49  60  65  66  78 110 137 141 158 174 192 199 210 213 231 235\n",
      " 254 261 266 286 296 302 306 307 309 311 314 316 326 328 334 342 352 361\n",
      " 371 381 405 423 428 430 433 442 447 482 483 493 507 525 531 543 545 570\n",
      " 572 576 594 602 605 606 615 625 630 685 689 694 707 732 735 736 737 746\n",
      " 780 784 788 813 814 817 819 820 835 838 852 854 866 872 886 889 896 904\n",
      " 910 925 941 944 945]\n",
      "TEST: [  2   5   7  10  25  29  54  55  77  81  82  84  97 101 109 118 155 196\n",
      " 204 211 227 228 239 244 281 318 319 321 323 344 346 350 355 357 380 398\n",
      " 408 411 412 420 424 425 444 451 456 468 494 514 516 526 529 536 544 549\n",
      " 551 568 580 587 596 603 611 613 621 626 629 652 660 666 668 677 680 687\n",
      " 692 711 721 723 754 755 757 770 781 795 810 822 825 843 844 857 864 882\n",
      " 895 897 907 921 922]\n",
      "TEST: [  0   6  18  24  28  41  51  56  61  69  73  79  83  90 108 125 131 132\n",
      " 133 135 140 144 145 148 164 169 172 173 181 185 193 212 220 234 238 264\n",
      " 272 274 285 290 291 299 300 305 338 351 359 362 367 370 382 422 429 432\n",
      " 448 477 479 485 490 497 499 522 532 533 535 538 575 578 585 604 618 634\n",
      " 635 669 678 713 731 734 751 758 759 824 827 846 847 853 869 873 878 884\n",
      " 887 890 898 936 937]\n",
      "TEST: [  3   9  11  12  15  22  42  43  74  89  92  94 100 104 113 114 163 167\n",
      " 176 177 178 179 182 221 222 223 248 249 256 257 278 289 324 329 335 336\n",
      " 354 356 360 368 375 383 390 393 395 396 404 409 416 417 426 436 440 462\n",
      " 467 501 506 530 534 539 542 547 552 557 567 582 583 597 601 622 628 631\n",
      " 636 662 670 705 716 717 718 740 752 760 774 806 828 833 834 837 870 881\n",
      " 902 909 933 935 938]\n",
      "TEST: [ 17  19  38  46  50  57  68  75  93 116 117 124 126 142 149 153 154 175\n",
      " 184 188 195 203 236 237 245 263 268 271 277 284 287 304 320 340 341 349\n",
      " 353 369 399 407 431 434 443 445 446 450 470 473 486 487 512 521 523 528\n",
      " 537 548 558 581 588 590 593 595 598 633 656 657 664 667 693 697 703 714\n",
      " 745 749 761 765 773 785 787 789 790 793 829 845 851 862 867 876 894 903\n",
      " 914 924 929 930 946]\n",
      "TEST: [  8  16  26  36  37  45  48  53 103 111 115 119 127 150 151 152 157 162\n",
      " 171 180 190 194 207 225 226 229 253 255 262 283 297 301 303 322 364 374\n",
      " 403 414 419 421 437 452 469 480 503 511 515 517 571 579 584 586 610 620\n",
      " 623 638 640 649 650 651 655 665 672 675 682 688 704 706 710 715 722 739\n",
      " 741 756 764 786 796 799 800 808 842 859 891 893 899 900 911 912 913 915\n",
      " 916 917 918 920 931]\n",
      "TEST: [112 122 123 129 143 146 147 183 186 197 202 219 224 232 233 246 258 267\n",
      " 279 282 293 317 325 347 348 358 373 376 384 386 400 402 410 415 438 441\n",
      " 463 472 488 496 505 509 550 556 607 608 609 619 624 627 632 637 639 641\n",
      " 645 648 659 671 676 691 696 709 712 720 728 730 743 744 750 794 797 798\n",
      " 801 807 809 823 836 839 849 855 861 863 865 868 877 879 880 888 901 906\n",
      " 919 928 934 940]\n",
      "TEST: [  4  14  27  32  35  40  47  52  62  64  85  95  98 128 134 138 156 159\n",
      " 170 187 200 206 216 217 230 240 242 251 269 288 295 337 378 379 391 392\n",
      " 397 406 418 455 460 461 471 489 492 498 502 520 524 540 546 553 563 573\n",
      " 574 577 592 612 642 647 654 674 683 690 698 701 719 724 725 726 727 733\n",
      " 738 742 748 763 766 768 772 779 791 802 803 811 812 815 830 832 841 848\n",
      " 892 905 923 943]\n",
      "TEST: [  1  13  20  21  34  58  71  80  87  91  99 102 105 106 121 130 160 161\n",
      " 166 189 191 201 205 214 241 243 252 270 273 276 308 313 315 330 339 343\n",
      " 345 366 372 385 387 389 401 413 427 435 454 458 459 466 474 475 476 484\n",
      " 491 504 508 510 555 560 561 562 564 565 566 600 614 646 661 663 681 686\n",
      " 699 700 702 729 747 769 771 775 776 782 805 818 821 831 840 856 860 871\n",
      " 875 885 927 939]\n"
     ]
    }
   ],
   "source": [
    "y_rf_socio_predict = []\n",
    "y_true = []\n",
    "\n",
    "ten_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in ten_fold.split(X_socio_2):\n",
    "    print(\"TEST:\", test_index)\n",
    "\n",
    "    X_train_1, X_test_1 = X_socio_2.iloc[train_index], X_socio_2.iloc[test_index]\n",
    "    y_train, y_test = Y_2.iloc[train_index], Y_2.iloc[test_index]\n",
    "    X_train = X_train_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density']]\n",
    "    X_test = X_test_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density']]\n",
    "    xy_coord = X_train_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    train_index_1 = X_train.index\n",
    "    train_index = pd.Series(train_index_1)\n",
    "    coords_test = X_test_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    grf = GeographicalRandomForest(890, 10, 377, 0.5, local_model_num = 40) # need to change\n",
    "    grf.fit(scaled_X_train, y_train, xy_coord, train_index)\n",
    "    \n",
    "    predict_combined, predict_global, predict_local = grf.predict(scaled_X_test,coords_test)\n",
    "    y_rf_socio_predict = y_rf_socio_predict + predict_combined\n",
    "    y_true = y_true + y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ec0844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the RF model with sociodemographic predictors: 1.203717344914799\n",
      "R2 of the RF model with sociodemographic predictors: 0.9509605556367354\n"
     ]
    }
   ],
   "source": [
    "rf_socio_rmse = mean_squared_error(y_true , y_rf_socio_predict, squared=False) #False means return RMSE value\n",
    "rf_socio_r2 = r2_score(y_true, y_rf_socio_predict)\n",
    "# sociodemographic - estimators\n",
    "print(\"RMSE of the RF model with sociodemographic predictors: \"+str(rf_socio_rmse))\n",
    "print(\"R2 of the RF model with sociodemographic predictors: \"+str(rf_socio_r2)) # For R2, I took this one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
