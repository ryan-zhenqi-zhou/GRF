{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cee863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for GRF, socio variables\n",
    "# Take Dataset3 BUF for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61530df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ac6a9",
   "metadata": {},
   "source": [
    "# Geographical RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9590cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeographicalRandomForest:\n",
    "    # this is the initialization function\n",
    "    # param local_model_num controls how many local models will participate in prediction; default is 1 !!!New\n",
    "    def __init__(self, ntree, mtry, band_width, local_weight, local_model_num=1, bootstrap=False, random_seed=42):\n",
    "        self.ntree = ntree\n",
    "        self.mtry = mtry\n",
    "        self.band_width = band_width\n",
    "        self.local_weight = local_weight\n",
    "        self.local_model_num = local_model_num\n",
    "        self.bootstrap=bootstrap\n",
    "        self.random_seed = random_seed\n",
    "        self.global_model = None\n",
    "        self.local_models = None\n",
    "        self.train_data_coords = None\n",
    "        self.distance_matrix = None\n",
    "        self.train_data_index = None\n",
    "        self.train_data_columns = None\n",
    "       \n",
    "    \n",
    "    # param X_train contains a data frame of the the training indepdent variables \n",
    "    # param y_train contains a data series of the target dependent variable\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    # param record_index contains a data series of the indices of the data for helping store local models\n",
    "    def fit(self, X_train, y_train, coords, record_index):\n",
    "        \n",
    "        # save the index of the training data\n",
    "        self.train_data_index = record_index\n",
    "        self.train_data_columns = X_train.columns\n",
    "        \n",
    "        # get Global RF model and importance information, and save global RF model\n",
    "        rf_global = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = self.ntree, max_features = self.mtry, random_state = self.random_seed) \n",
    "        rf_global.fit(X_train, y_train)\n",
    "        self.global_model = rf_global\n",
    "        \n",
    "        \n",
    "        # create an empty dictionary for local models\n",
    "        self.local_models = {}\n",
    "        \n",
    "        # get the distance matrix between the training geographic features\n",
    "        coords_array = np.array(coords, dtype = np.float64) # translate (x,y) to array type\n",
    "        self.train_data_coords = coords_array\n",
    "        self.distance_matrix = distance.cdist(coords_array,coords_array, 'euclidean') # calculate Euclidean Distance\n",
    "        \n",
    "        # train local models\n",
    "        for i in range(len(X_train)):\n",
    "            distance_array = self.distance_matrix[i]\n",
    "            idx = np.argpartition(distance_array, self.band_width)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.band_width]  # only those indices within the band_width are valid \n",
    "            \n",
    "            local_X_train = X_train.iloc[idx]\n",
    "            local_y_train = y_train.iloc[idx]\n",
    "            \n",
    "            # make local tree size smaller, because there is no sufficient data to train a big tree !!!New\n",
    "            local_tree_size = int(self.ntree * (self.band_width*1.0/len(X_train)))\n",
    "            if local_tree_size < 1:\n",
    "                local_tree_size = 1  # local tree size should be at least 1\n",
    "             \n",
    "            # get local model\n",
    "            rf_local = RandomForestRegressor(bootstrap = self.bootstrap, n_estimators = local_tree_size, max_features = self.mtry, random_state = self.random_seed) # input\n",
    "            rf_local.fit(local_X_train, local_y_train)\n",
    "            \n",
    "            # key for storing local rf model in a dictionary\n",
    "            rf_local_key = str(record_index.iloc[i])+\"|\"+ str(coords_array[i][0])+\"|\"+str(coords_array[i][1])\n",
    "            self.local_models[rf_local_key] = rf_local\n",
    "            \n",
    "    \n",
    "    # the function for making predictions using the GRF model\n",
    "    # param X_test contains a data frame of the independent variables in the test dataset\n",
    "    # param coords contains a data frame of the two-dimensional coordinates\n",
    "    def predict(self, X_test, coords_test): \n",
    "        \n",
    "        # first, make prediction using the global RF model \n",
    "        predict_global = self.global_model.predict(X_test).flatten() # get the global predict y first\n",
    "        \n",
    "        # Second, make prediction using the local RF model \n",
    "        coords_test_array = np.array(coords_test, dtype = np.float64)\n",
    "        distance_matrix_test_to_train = distance.cdist(coords_test_array, self.train_data_coords, 'euclidean')\n",
    "        predict_local = []\n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            distance_array = distance_matrix_test_to_train[i]\n",
    "            idx = np.argpartition(distance_array, self.local_model_num)  # Get the index of the geographic features that are the nearest to the target geographic feature\n",
    "            idx = idx[:self.local_model_num]\n",
    "            \n",
    "            this_local_prediction = 0\n",
    "            for this_idx in idx:\n",
    "                local_model_key = str(self.train_data_index.iloc[this_idx])+\"|\"+ str(self.train_data_coords[this_idx][0])+\"|\"+str(self.train_data_coords[this_idx][1])\n",
    "                local_model = self.local_models[local_model_key]\n",
    "                this_local_prediction += local_model.predict(X_test[i:i+1]).flatten()[0]\n",
    "            \n",
    "            this_local_prediction = this_local_prediction*1.0 / self.local_model_num  # average local predictions\n",
    "            predict_local.append(this_local_prediction)\n",
    "          \n",
    "        \n",
    "        # Third, combine global and local predictions\n",
    "        predict_combined = []\n",
    "        for i in range(len(predict_global)):\n",
    "            this_combined_prediction = predict_local[i]*self.local_weight + predict_global[i]*(1-self.local_weight) \n",
    "            predict_combined.append(this_combined_prediction)\n",
    "        \n",
    "        \n",
    "        return predict_combined, predict_global, predict_local   # return three types of predictions\n",
    "    \n",
    "    \n",
    "    # this function outputs the local feature importance based on the local models\n",
    "    def get_local_feature_importance(self):\n",
    "        if self.local_models == None:\n",
    "            print(\"The model has not been trained yet...\")\n",
    "            return None\n",
    "        \n",
    "        column_list = [self.train_data_index.name] \n",
    "        for column_name in self.train_data_columns: \n",
    "            column_list.append(column_name) \n",
    "            \n",
    "        feature_importance_df = pd.DataFrame(columns = column_list) \n",
    "        \n",
    "        for model_key in self.local_models.keys():\n",
    "            model_info = model_key.split(\"|\")\n",
    "            this_local_model = self.local_models[model_key]\n",
    "            this_row = {}\n",
    "            this_row[self.train_data_index.name] = model_info[0] # the index of a row\n",
    "            for feature_index in range(0, len(self.train_data_columns)):\n",
    "                this_row[self.train_data_columns[feature_index]]=this_local_model.feature_importances_[feature_index]\n",
    "            \n",
    "            feature_importance_df = feature_importance_df.append(this_row, ignore_index = True) # TypeError: Can only append a dict if ignore_index=True\n",
    "            \n",
    "            \n",
    "        return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162d4a7",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f012a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_compl = pd.read_csv(\"../02 Dataset/05 Dataset 3/Complete_BUF.csv\") #input\n",
    "ct_shp = gpd.read_file(\"../02 Dataset/07 Coordinates info for GWR/BUF_CDC data_Tract_Ob_pro.shp\") # input\n",
    "ct_shp['GEOID'] = ct_shp['GEOID'].astype('int64')\n",
    "X_compl_1 = X_compl.merge(ct_shp, left_on = 'GEOID', right_on = 'GEOID', how = 'left')\n",
    "X_compl_2 = X_compl_1.set_index('GEOID')\n",
    "Y_2 = X_compl_2.pop('obesity_cr')\n",
    "del X_compl_2['geometry']\n",
    "len(X_compl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1871b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['% Black',\n",
       " '% Ame Indi and AK Native',\n",
       " '% Asian',\n",
       " '% Nati Hawa and Paci Island',\n",
       " '% Hispanic or Latino',\n",
       " '% male',\n",
       " '% married',\n",
       " '% age 18-29',\n",
       " '% age 30-39',\n",
       " '% age 40-49',\n",
       " '% age 50-59',\n",
       " '% age >=60',\n",
       " '% <highschool',\n",
       " 'median income',\n",
       " '% unemployment',\n",
       " '% below poverty line',\n",
       " '% food stamp/SNAP',\n",
       " 'median value units built',\n",
       " 'median year units built',\n",
       " '% renter-occupied housing units',\n",
       " 'population density',\n",
       " 'fafood',\n",
       " 'fitness',\n",
       " 'park',\n",
       " 'Lonpro',\n",
       " 'Latpro']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_compl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c70a1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Black</th>\n",
       "      <th>% Ame Indi and AK Native</th>\n",
       "      <th>% Asian</th>\n",
       "      <th>% Nati Hawa and Paci Island</th>\n",
       "      <th>% Hispanic or Latino</th>\n",
       "      <th>% male</th>\n",
       "      <th>% married</th>\n",
       "      <th>% age 18-29</th>\n",
       "      <th>% age 30-39</th>\n",
       "      <th>% age 40-49</th>\n",
       "      <th>...</th>\n",
       "      <th>% food stamp/SNAP</th>\n",
       "      <th>median value units built</th>\n",
       "      <th>median year units built</th>\n",
       "      <th>% renter-occupied housing units</th>\n",
       "      <th>population density</th>\n",
       "      <th>fafood</th>\n",
       "      <th>fitness</th>\n",
       "      <th>park</th>\n",
       "      <th>Lonpro</th>\n",
       "      <th>Latpro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36029000500</th>\n",
       "      <td>0.062950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153477</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.118106</td>\n",
       "      <td>0.126499</td>\n",
       "      <td>0.083933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331218</td>\n",
       "      <td>50800</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.376904</td>\n",
       "      <td>266.853532</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>0.218783</td>\n",
       "      <td>0.561366</td>\n",
       "      <td>183911.0</td>\n",
       "      <td>4753020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029000700</th>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029076</td>\n",
       "      <td>0.454891</td>\n",
       "      <td>0.472657</td>\n",
       "      <td>0.165761</td>\n",
       "      <td>0.135870</td>\n",
       "      <td>0.111685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100134</td>\n",
       "      <td>125300</td>\n",
       "      <td>1944</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>3437.581736</td>\n",
       "      <td>0.421502</td>\n",
       "      <td>0.413855</td>\n",
       "      <td>0.769681</td>\n",
       "      <td>188844.0</td>\n",
       "      <td>4749760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029000900</th>\n",
       "      <td>0.005390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180763</td>\n",
       "      <td>0.484245</td>\n",
       "      <td>0.391390</td>\n",
       "      <td>0.207711</td>\n",
       "      <td>0.227612</td>\n",
       "      <td>0.093284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135734</td>\n",
       "      <td>93000</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.445060</td>\n",
       "      <td>4384.936326</td>\n",
       "      <td>0.288562</td>\n",
       "      <td>0.307975</td>\n",
       "      <td>0.621196</td>\n",
       "      <td>188168.0</td>\n",
       "      <td>4751660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029001000</th>\n",
       "      <td>0.092095</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055094</td>\n",
       "      <td>0.515729</td>\n",
       "      <td>0.427102</td>\n",
       "      <td>0.193154</td>\n",
       "      <td>0.168867</td>\n",
       "      <td>0.082967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317936</td>\n",
       "      <td>79400</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.520183</td>\n",
       "      <td>2932.488101</td>\n",
       "      <td>0.362364</td>\n",
       "      <td>0.232738</td>\n",
       "      <td>0.713865</td>\n",
       "      <td>189081.0</td>\n",
       "      <td>4751290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029001100</th>\n",
       "      <td>0.057063</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105428</td>\n",
       "      <td>0.525052</td>\n",
       "      <td>0.324919</td>\n",
       "      <td>0.186152</td>\n",
       "      <td>0.134308</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239050</td>\n",
       "      <td>74300</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.543430</td>\n",
       "      <td>1885.467988</td>\n",
       "      <td>0.342703</td>\n",
       "      <td>0.188468</td>\n",
       "      <td>0.791351</td>\n",
       "      <td>188339.0</td>\n",
       "      <td>4752650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              % Black  % Ame Indi and AK Native   % Asian  \\\n",
       "GEOID                                                       \n",
       "36029000500  0.062950                  0.000000  0.000000   \n",
       "36029000700  0.004076                  0.000000  0.007337   \n",
       "36029000900  0.005390                  0.000000  0.005390   \n",
       "36029001000  0.092095                  0.034719  0.016137   \n",
       "36029001100  0.057063                  0.015310  0.032359   \n",
       "\n",
       "             % Nati Hawa and Paci Island  % Hispanic or Latino    % male  \\\n",
       "GEOID                                                                      \n",
       "36029000500                          0.0              0.153477  0.432854   \n",
       "36029000700                          0.0              0.029076  0.454891   \n",
       "36029000900                          0.0              0.180763  0.484245   \n",
       "36029001000                          0.0              0.055094  0.515729   \n",
       "36029001100                          0.0              0.105428  0.525052   \n",
       "\n",
       "             % married  % age 18-29  % age 30-39  % age 40-49  ...  \\\n",
       "GEOID                                                          ...   \n",
       "36029000500   0.361005     0.118106     0.126499     0.083933  ...   \n",
       "36029000700   0.472657     0.165761     0.135870     0.111685  ...   \n",
       "36029000900   0.391390     0.207711     0.227612     0.093284  ...   \n",
       "36029001000   0.427102     0.193154     0.168867     0.082967  ...   \n",
       "36029001100   0.324919     0.186152     0.134308     0.092206  ...   \n",
       "\n",
       "             % food stamp/SNAP  median value units built  \\\n",
       "GEOID                                                      \n",
       "36029000500           0.331218                     50800   \n",
       "36029000700           0.100134                    125300   \n",
       "36029000900           0.135734                     93000   \n",
       "36029001000           0.317936                     79400   \n",
       "36029001100           0.239050                     74300   \n",
       "\n",
       "             median year units built  % renter-occupied housing units  \\\n",
       "GEOID                                                                   \n",
       "36029000500                     1939                         0.376904   \n",
       "36029000700                     1944                         0.242323   \n",
       "36029000900                     1939                         0.445060   \n",
       "36029001000                     1939                         0.520183   \n",
       "36029001100                     1939                         0.543430   \n",
       "\n",
       "             population density    fafood   fitness      park    Lonpro  \\\n",
       "GEOID                                                                     \n",
       "36029000500          266.853532  0.243330  0.218783  0.561366  183911.0   \n",
       "36029000700         3437.581736  0.421502  0.413855  0.769681  188844.0   \n",
       "36029000900         4384.936326  0.288562  0.307975  0.621196  188168.0   \n",
       "36029001000         2932.488101  0.362364  0.232738  0.713865  189081.0   \n",
       "36029001100         1885.467988  0.342703  0.188468  0.791351  188339.0   \n",
       "\n",
       "                Latpro  \n",
       "GEOID                   \n",
       "36029000500  4753020.0  \n",
       "36029000700  4749760.0  \n",
       "36029000900  4751660.0  \n",
       "36029001000  4751290.0  \n",
       "36029001100  4752650.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_compl_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda9ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(data, stats):\n",
    "    return (data - stats['mean'])/ stats['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943fca1",
   "metadata": {},
   "source": [
    "# GRF 10K-Fold local_w = 1, local_model_num = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3cf1972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flod: 1\n",
      "flod: 2\n",
      "flod: 3\n",
      "flod: 4\n",
      "flod: 5\n",
      "flod: 6\n",
      "flod: 7\n",
      "flod: 8\n",
      "flod: 9\n",
      "flod: 10\n"
     ]
    }
   ],
   "source": [
    "y_rf_compl_predict = []\n",
    "y_true = []\n",
    "dfs = []\n",
    "\n",
    "ten_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in ten_fold.split(X_compl_2):\n",
    "    print(\"flod:\", str(i))\n",
    "\n",
    "    X_train_1, X_test_1 = X_compl_2.iloc[train_index], X_compl_2.iloc[test_index]\n",
    "    y_train, y_test = Y_2.iloc[train_index], Y_2.iloc[test_index]\n",
    "    X_train = X_train_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density','fafood','fitness','park']]\n",
    "    X_test = X_test_1[['% Black','% Ame Indi and AK Native','% Asian','% Nati Hawa and Paci Island','% Hispanic or Latino','% male','% married','% age 18-29','% age 30-39','% age 40-49','% age 50-59','% age >=60','% <highschool','median income','% unemployment','% below poverty line','% food stamp/SNAP','median value units built','median year units built','% renter-occupied housing units','population density','fafood','fitness','park']]\n",
    "    xy_coord = X_train_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    train_index_1 = X_train.index\n",
    "    train_index = pd.Series(train_index_1)\n",
    "    coords_test = X_test_1[[\"Lonpro\",\"Latpro\"]]\n",
    "    \n",
    "    training_stat = X_train.describe().transpose()\n",
    "    scaled_X_train = standarize_data(X_train, training_stat)\n",
    "    scaled_X_test = standarize_data(X_test, training_stat)\n",
    "    \n",
    "    grf = GeographicalRandomForest(160, 'sqrt', 68, 1, local_model_num = 37) \n",
    "    grf.fit(scaled_X_train, y_train, xy_coord, train_index)\n",
    "    \n",
    "    predict_combined, predict_global, predict_local = grf.predict(scaled_X_test,coords_test)\n",
    "    \n",
    "    local_feature_importance = grf.get_local_feature_importance()\n",
    "    # local_feature_importance.to_csv(\"../02 Dataset/09 GRF Local Importance/01 NYC/lfi_{}.csv\".format(i))\n",
    "    dfs.append(local_feature_importance)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    y_rf_compl_predict = y_rf_compl_predict + predict_combined\n",
    "    y_true = y_true + y_test.tolist()\n",
    "    \n",
    "local_feature_importance1 = pd.concat(dfs)\n",
    "local_feature_importance2 = local_feature_importance1[['GEOID','fafood','fitness','park']]\n",
    "local_feature_importance_last = local_feature_importance2.groupby([\"GEOID\"]).agg({\"fafood\":\"mean\",\"fitness\":\"mean\",\"park\":\"mean\"}).reset_index()\n",
    "local_feature_importance_last.to_csv('../02 Dataset/09 GRF Local Importance/local_feature_importance_BUF.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97cd3c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the RF model with all predictors: 2.4559245533870717\n",
      "R2 of the RF model with all predictors: 0.875314566662232\n"
     ]
    }
   ],
   "source": [
    "rf_complete_rmse = mean_squared_error(y_true , y_rf_compl_predict, squared=False) #False means return RMSE value\n",
    "rf_complete_r2 = r2_score(y_true, y_rf_compl_predict)\n",
    "# sociodemographic - estimators\n",
    "print(\"RMSE of the RF model with all predictors: \"+str(rf_complete_rmse))\n",
    "print(\"R2 of the RF model with all predictors: \"+str(rf_complete_r2)) # For R2, I took this one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
